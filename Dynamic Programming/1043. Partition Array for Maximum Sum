Given an integer array arr, partition the array into (contiguous) subarrays of length at most k. After partitioning, each subarray has their values changed to become the maximum value of that subarray.

Return the largest sum of the given array after partitioning. Test cases are generated so that the answer fits in a 32-bit integer.

 

Example 1:

Input: arr = [1,15,7,9,2,5,10], k = 3
Output: 84
Explanation: arr becomes [15,15,15,9,10,10,10]
Example 2:

Input: arr = [1,4,1,5,7,3,6,1,9,9,3], k = 4
Output: 83
Example 3:

Input: arr = [1], k = 1
Output: 1
 

Constraints:

1 <= arr.length <= 500
0 <= arr[i] <= 109
1 <= k <= arr.length


Approach:
In this question, we use Dynamic Programming.
For every position 'i', the maximum sum is the max(arr[i : k]) * (k) where 0 <= k < n

So we just carry the maximum values of each subarray from end of the array to start of the array.


recurrence will be:
for i in range(i, i + k):
    maximum_element = max(maximum_element, arr[i])
    max_sum = max(max_sum, maximum_element * (i - curr_index + 1) + dfs(i + 1))



Code:
class Solution:
    def maxSumAfterPartitioning(self, arr: List[int], k: int) -> int:
        def dfs(start):
            if start >= n:
                return 0
            
            if start in dp:
                return dp[start]
            
            max_ele = 0
            max_sum = 0
            for i in range(start, min(start + k, n)):
                max_ele = max(max_ele, arr[i])
                max_sum = max(max_sum, max_ele * (i - start + 1) + dfs(i + 1))
            dp[start] = max_sum
            return max_sum
        
        n = len(arr)
        dp = defaultdict(int)
        return dfs(0)
